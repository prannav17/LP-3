# -*- coding: utf-8 -*-
"""Pract - 3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zSgwZFOVnMzQP6aiQbbUz9qjlBklmpa8
"""

# Install necessary libraries
!pip install pandas matplotlib seaborn scikit-learn tensorflow

# Import libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import MinMaxScaler, StandardScaler
from sklearn.model_selection import train_test_split

# Load the dataset
df = pd.read_csv('/content/Churn_Modelling.csv')
df.head()

# Drop unnecessary columns
df.drop(['RowNumber', 'Surname'], axis='columns', inplace=True)

# Check for null values
print(df.isna().sum())

# Check data types
print(df.dtypes)

# Unique values in Geography and Gender columns
print(df['Geography'].unique())
print(df['Gender'].unique())

# Encode Gender
df['Gender'] = df['Gender'].map({'Male': 1, 'Female': 0})

# One hot encoding for Geography
df = pd.get_dummies(data=df, columns=['Geography'], drop_first=True)

# Check data types after encoding
print(df.dtypes)

# Value counts of Exited column
print(df['Exited'].value_counts())

# Visualization function
def visualization(x, y, xlabel):
    plt.figure(figsize=(10, 5))
    plt.hist([x, y], color=['red', 'green'], label=['Exited', 'Not Exited'])
    plt.xlabel(xlabel, fontsize=20)
    plt.ylabel("Number of Customers", fontsize=20)
    plt.legend()

# Visualize Tenure distribution
df_exited = df[df['Exited'] == 1]['Tenure']
df_not_exited = df[df['Exited'] == 0]['Tenure']
visualization(df_exited, df_not_exited, "Tenure")

# Visualize Age distribution
df_exited_age = df[df['Exited'] == 1]['Age']
df_not_exited_age = df[df['Exited'] == 0]['Age']
visualization(df_exited_age, df_not_exited_age, "Age")

# Normalization
cols_to_scale = ['CustomerId', 'CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']
scaler = MinMaxScaler()
df[cols_to_scale] = scaler.fit_transform(df[cols_to_scale])

# Separate outcome or target column
X = df.drop(['Exited'], axis=1)
y = df['Exited']

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

# Feature scaling
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Import TensorFlow and Keras
import tensorflow as tf
from tensorflow import keras

# Install necessary libraries
!pip install pandas matplotlib seaborn scikit-learn tensorflow

# Import libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import MinMaxScaler, StandardScaler
from sklearn.model_selection import train_test_split

# Load the dataset
df = pd.read_csv('/content/Churn_Modelling.csv')
df.head()

# Drop unnecessary columns
df.drop(['RowNumber', 'Surname'], axis='columns', inplace=True)

# Check for null values
print(df.isna().sum())

# Check data types
print(df.dtypes)

# Unique values in Geography and Gender columns
print(df['Geography'].unique())
print(df['Gender'].unique())

# Encode Gender without using inplace
df['Gender'] = df['Gender'].map({'Male': 1, 'Female': 0})

# One hot encoding for Geography
df = pd.get_dummies(data=df, columns=['Geography'], drop_first=True)

# Check data types after encoding
print(df.dtypes)

# Value counts of Exited column
print(df['Exited'].value_counts())

# Visualization function
def visualization(x, y, xlabel):
    plt.figure(figsize=(10, 5))
    plt.hist([x, y], color=['red', 'green'], label=['Exited', 'Not Exited'])
    plt.xlabel(xlabel, fontsize=20)
    plt.ylabel("Number of Customers", fontsize=20)
    plt.legend()

# Visualize Tenure distribution
df_exited = df[df['Exited'] == 1]['Tenure']
df_not_exited = df[df['Exited'] == 0]['Tenure']
visualization(df_exited, df_not_exited, "Tenure")

# Visualize Age distribution
df_exited_age = df[df['Exited'] == 1]['Age']
df_not_exited_age = df[df['Exited'] == 0]['Age']
visualization(df_exited_age, df_not_exited_age, "Age")

# Normalization
cols_to_scale = ['CustomerId', 'CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']
scaler = MinMaxScaler()
df[cols_to_scale] = scaler.fit_transform(df[cols_to_scale])

# Separate outcome or target column
X = df.drop(['Exited'], axis=1)
y = df['Exited']

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

# Feature scaling
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Import TensorFlow and Keras
import tensorflow as tf
from tensorflow import keras

